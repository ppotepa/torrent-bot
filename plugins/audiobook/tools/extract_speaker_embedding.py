#!/usr/bin/env python3
"""
Speaker Embedding Extraction - Ekstrakcja cech gÅ‚osu dla OpenVoice
"""

import os
import torch
import torchaudio
import numpy as np
import logging
from pathlib import Path
from typing import Optional, Dict, Any, List
import glob

# OpenVoice imports
try:
    from openvoice import se_extractor
    from openvoice.api import ToneColorConverter
    OPENVOICE_AVAILABLE = True
except ImportError:
    OPENVOICE_AVAILABLE = False

logger = logging.getLogger(__name__)

class SpeakerEmbeddingExtractor:
    """Ekstraktor cech gÅ‚osu uÅ¼ywajÄ…cy OpenVoice"""
    
    def __init__(self, openvoice_dir="models/openvoice"):
        self.openvoice_dir = Path(openvoice_dir)
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # ÅšcieÅ¼ki do modeli OpenVoice
        self.ckpt_converter = self.openvoice_dir / "converter"
        
        # Speaker embedding extractor
        self.se_extractor = None
        self.tone_converter = None
        
        # SprawdÅº dostÄ™pnoÅ›Ä‡
        self.available = self._check_availability()
        
    def _check_availability(self) -> bool:
        """Sprawdza czy OpenVoice jest dostÄ™pny"""
        if not OPENVOICE_AVAILABLE:
            logger.warning("OpenVoice nie jest zainstalowany")
            return False
            
        if not self.ckpt_converter.exists():
            logger.warning(f"Converter model nie znaleziony: {self.ckpt_converter}")
            return False
            
        return True
    
    def is_available(self) -> bool:
        """Zwraca czy ekstraktor jest dostÄ™pny"""
        return self.available
    
    def initialize_models(self) -> bool:
        """Inicjalizuje modele OpenVoice"""
        if not self.available:
            return False
            
        try:
            # Inicjalizacja tone converter
            logger.info("Inicjalizacja OpenVoice ToneColorConverter...")
            self.tone_converter = ToneColorConverter(f'{self.ckpt_converter}/config.json', device=self.device)
            self.tone_converter.load_ckpt(f'{self.ckpt_converter}/checkpoint.pth')
            
            # Inicjalizacja speaker embedding extractor
            logger.info("Inicjalizacja Speaker Embedding Extractor...")
            
            return True
            
        except Exception as e:
            logger.error(f"BÅ‚Ä…d inicjalizacji modeli OpenVoice: {e}")
            return False
    
    def extract_speaker_embedding(self, audio_paths: List[str], output_path: str) -> bool:
        """
        Ekstraktuje speaker embedding z prÃ³bek audio
        
        Args:
            audio_paths: Lista Å›cieÅ¼ek do plikÃ³w audio z referencyjnym gÅ‚osem
            output_path: ÅšcieÅ¼ka do zapisu embedding
            
        Returns:
            bool: True jeÅ›li sukces
        """
        if not self.available:
            logger.error("Speaker embedding extractor nie jest dostÄ™pny")
            return False
            
        if not self.tone_converter:
            if not self.initialize_models():
                return False
        
        try:
            logger.info(f"Ekstrakcja speaker embedding z {len(audio_paths)} prÃ³bek...")
            
            # ZaÅ‚aduj wszystkie prÃ³bki audio
            audio_tensors = []
            sample_rates = []
            
            for audio_path in audio_paths:
                if not os.path.exists(audio_path):
                    logger.warning(f"Plik nie istnieje: {audio_path}")
                    continue
                    
                logger.info(f"Åadowanie prÃ³bki: {audio_path}")
                audio, sr = torchaudio.load(audio_path)
                
                # Konwersja do mono jeÅ›li stereo
                if audio.shape[0] > 1:
                    audio = torch.mean(audio, dim=0, keepdim=True)
                
                audio_tensors.append(audio)
                sample_rates.append(sr)
            
            if not audio_tensors:
                logger.error("Brak prawidÅ‚owych prÃ³bek audio")
                return False
            
            # SprawdÅº czy wszystkie prÃ³bki majÄ… ten sam sample rate
            if len(set(sample_rates)) > 1:
                logger.warning(f"RÃ³Å¼ne sample rates: {sample_rates}, uÅ¼ywam pierwszego")
            
            target_sr = sample_rates[0]
            
            # PoÅ‚Ä…cz wszystkie prÃ³bki
            if len(audio_tensors) > 1:
                # Dopasuj dÅ‚ugoÅ›ci (padding/trimming)
                max_length = max(audio.shape[1] for audio in audio_tensors)
                padded_tensors = []
                
                for audio in audio_tensors:
                    if audio.shape[1] < max_length:
                        # Padding z zerami
                        pad_size = max_length - audio.shape[1]
                        audio = torch.nn.functional.pad(audio, (0, pad_size))
                    elif audio.shape[1] > max_length:
                        # Trim do max_length
                        audio = audio[:, :max_length]
                    padded_tensors.append(audio)
                
                # UÅ›rednij wszystkie prÃ³bki
                combined_audio = torch.mean(torch.stack(padded_tensors), dim=0)
            else:
                combined_audio = audio_tensors[0]
            
            # Zapisz poÅ‚Ä…czone audio do tymczasowego pliku
            temp_audio_path = output_path.replace('.pt', '_combined.wav')
            torchaudio.save(temp_audio_path, combined_audio, target_sr)
            
            logger.info(f"PoÅ‚Ä…czone audio zapisane: {temp_audio_path}")
            logger.info(f"KsztaÅ‚t: {combined_audio.shape}, Sample rate: {target_sr}")
            
            # Ekstraktuj speaker embedding uÅ¼ywajÄ…c OpenVoice
            logger.info("Ekstrakcja speaker embedding...")
            reference_speaker_embedding = se_extractor.get_se(
                temp_audio_path, 
                self.tone_converter, 
                vad=True  # Voice Activity Detection
            )
            
            # Zapisz embedding
            torch.save(reference_speaker_embedding, output_path)
            
            # Cleanup
            if os.path.exists(temp_audio_path):
                os.unlink(temp_audio_path)
            
            logger.info(f"Speaker embedding zapisany: {output_path}")
            logger.info(f"KsztaÅ‚t embedding: {reference_speaker_embedding.shape}")
            
            return True
            
        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas ekstrakcji speaker embedding: {e}")
            return False
    
    def load_speaker_embedding(self, embedding_path: str) -> Optional[torch.Tensor]:
        """Åaduje zapisany speaker embedding"""
        try:
            if not os.path.exists(embedding_path):
                logger.error(f"Embedding nie istnieje: {embedding_path}")
                return None
                
            embedding = torch.load(embedding_path, map_location=self.device)
            logger.info(f"ZaÅ‚adowano speaker embedding: {embedding.shape}")
            return embedding
            
        except Exception as e:
            logger.error(f"BÅ‚Ä…d Å‚adowania embedding: {e}")
            return None
    
    def get_info(self) -> Dict[str, Any]:
        """Zwraca informacje o ekstraktorze"""
        return {
            "name": "OpenVoice Speaker Embedding Extractor",
            "available": self.available,
            "device": self.device,
            "openvoice_dir": str(self.openvoice_dir),
            "converter_path": str(self.ckpt_converter)
        }

# Factory function
def get_speaker_extractor(openvoice_dir="models/openvoice") -> SpeakerEmbeddingExtractor:
    """Tworzy instancjÄ™ speaker embedding extractor"""
    return SpeakerEmbeddingExtractor(openvoice_dir)

if __name__ == "__main__":
    # Ustaw debug logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    # Test Speaker Embedding Extractor
    print("ğŸ™ï¸ Test Speaker Embedding Extractor")
    print("=" * 50)
    
    extractor = get_speaker_extractor()
    
    # Informacje
    print("Speaker Extractor Info:")
    for key, value in extractor.get_info().items():
        print(f"  {key}: {value}")
    
    if not extractor.is_available():
        print("âŒ Speaker Embedding Extractor nie jest dostÄ™pny!")
        exit(1)
    
    # Test ekstrakcji
    print("\nğŸ§ª Uruchamianie testu ekstrakcji...")
    
    # ZnajdÅº prÃ³bki gÅ‚osu
    voice_samples_dir = "voice_samples"
    if os.path.exists(voice_samples_dir):
        audio_files = glob.glob(os.path.join(voice_samples_dir, "reference_*.wav"))
        
        if audio_files:
            print(f"Znaleziono {len(audio_files)} prÃ³bek gÅ‚osu:")
            for f in audio_files:
                print(f"  - {f}")
            
            # Ekstraktuj speaker embedding
            output_embedding = "speaker_embedding.pt"
            success = extractor.extract_speaker_embedding(audio_files, output_embedding)
            
            if success:
                print("âœ… Test zakoÅ„czony sukcesem!")
                
                # Test Å‚adowania
                embedding = extractor.load_speaker_embedding(output_embedding)
                if embedding is not None:
                    print(f"âœ… Speaker embedding zaÅ‚adowany: {embedding.shape}")
                else:
                    print("âŒ BÅ‚Ä…d Å‚adowania embedding")
            else:
                print("âŒ Test nie powiÃ³dÅ‚ siÄ™!")
        else:
            print("âŒ Brak prÃ³bek gÅ‚osu w katalogu voice_samples/")
    else:
        print("âŒ Katalog voice_samples/ nie istnieje!")
