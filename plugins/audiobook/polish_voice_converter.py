#!/usr/bin/env python3
"""
Polish Voice Conversion Pipeline - Kompletny pipeline polskiego TTS z klonowaniem gÅ‚osu
"""

import os
import tempfile
import logging
from pathlib import Path
from typing import Optional, Dict, Any
import torch
import torchaudio

# Import naszych komponentÃ³w
from enhanced_piper_tts import get_piper_tts  # Enhanced version
from simple_speaker_embedding import get_speaker_extractor

logger = logging.getLogger(__name__)

class PolishVoiceConverter:
    """Kompletny pipeline polskiego TTS z klonowaniem gÅ‚osu"""
    
    def __init__(self, speaker_embedding_path: str = "simple_speaker_embedding.pt"):
        self.speaker_embedding_path = speaker_embedding_path
        
        # Komponenty pipeline
        self.piper_tts = get_piper_tts()
        self.speaker_extractor = get_speaker_extractor()
        
        # ZaÅ‚aduj speaker embedding
        self.speaker_embedding = None
        self._load_speaker_embedding()
        
        # SprawdÅº dostÄ™pnoÅ›Ä‡
        self.available = self._check_availability()
        
    def _load_speaker_embedding(self) -> bool:
        """Åaduje speaker embedding z pliku"""
        if not os.path.exists(self.speaker_embedding_path):
            logger.warning(f"Speaker embedding nie znaleziony: {self.speaker_embedding_path}")
            return False
            
        self.speaker_embedding = self.speaker_extractor.load_speaker_embedding(self.speaker_embedding_path)
        if self.speaker_embedding is not None:
            logger.info(f"ZaÅ‚adowano speaker embedding: {self.speaker_embedding.shape}")
            return True
        return False
        
    def _check_availability(self) -> bool:
        """Sprawdza czy pipeline jest dostÄ™pny"""
        if not self.piper_tts.is_available():
            logger.warning("Piper TTS nie jest dostÄ™pny")
            return False
            
        if not self.speaker_extractor.is_available():
            logger.warning("Speaker extractor nie jest dostÄ™pny")
            return False
            
        if self.speaker_embedding is None:
            logger.warning("Speaker embedding nie zostaÅ‚ zaÅ‚adowany")
            return False
            
        return True
    
    def is_available(self) -> bool:
        """Zwraca czy pipeline jest dostÄ™pny"""
        return self.available
    
    def simple_voice_processing(self, base_audio_path: str, output_path: str) -> bool:
        """
        ğŸ­ ULEPSZONE VOICE PROCESSING - redukcja robotycznego dÅºwiÄ™ku
        
        Args:
            base_audio_path: ÅšcieÅ¼ka do bazowego audio z Enhanced Piper
            output_path: ÅšcieÅ¼ka do zapisu przetworzonego audio
            
        Returns:
            bool: True jeÅ›li sukces
        """
        try:
            logger.info("ğŸ­ Aplikowanie ulepszonego voice processing...")
            
            # ZaÅ‚aduj bazowe audio
            audio, sr = torchaudio.load(base_audio_path)
            
            # === ULEPSZONE VOICE PROCESSING ===
            
            # 1. ğŸ¯ Inteligentna redukcja robotycznego dÅºwiÄ™ku
            # Lekka denormalizacja dla naturalnoÅ›ci
            audio = audio * 0.95  # Lekko ciszej
            
            # 2. ğŸµ Naturalna modulacja amplitudy (symulacja oddechu)
            import numpy as np
            from scipy import signal
            
            audio_np = audio.numpy()
            
            # Generuj subtelnÄ… modulacjÄ™ amplitudy (4-6 Hz - naturalna czÄ™stoÅ›Ä‡ oddechu)
            modulation_freq = 5.0  # Hz
            t = np.linspace(0, audio_np.shape[1] / sr, audio_np.shape[1])
            amplitude_modulation = 1.0 + 0.02 * np.sin(2 * np.pi * modulation_freq * t)
            
            # Aplikuj modulacjÄ™ do kaÅ¼dego kanaÅ‚u
            for channel in range(audio_np.shape[0]):
                audio_np[channel] *= amplitude_modulation
            
            # 3. ğŸšï¸ Subtelny EQ dla naturalnoÅ›ci gÅ‚osu
            # Boost czÄ™stotliwoÅ›ci wokalnych (1-3 kHz) i lekko obniÅ¼ wysokie
            nyquist = sr // 2
            
            # Filtr shelf dla wysokich czÄ™stotliwoÅ›ci (powyÅ¼ej 4kHz)
            high_freq = 4000 / nyquist
            if high_freq < 1.0:
                b_high, a_high = signal.butter(2, high_freq, btype='highpass')
                
                # Filtr boost dla czÄ™stotliwoÅ›ci wokalnych (800-3000 Hz)
                low_vocal = 800 / nyquist
                high_vocal = 3000 / nyquist
                
                if low_vocal < 1.0 and high_vocal < 1.0:
                    b_vocal, a_vocal = signal.butter(2, [low_vocal, high_vocal], btype='band')
                    
                    # Aplikuj filtry do kaÅ¼dego kanaÅ‚u
                    processed_audio = np.zeros_like(audio_np)
                    for channel in range(audio_np.shape[0]):
                        # Boost Å›rednich czÄ™stotliwoÅ›ci wokalnych
                        vocal_boost = signal.filtfilt(b_vocal, a_vocal, audio_np[channel])
                        
                        # Lekko obniÅ¼ wysokie czÄ™stotliwoÅ›ci
                        high_content = signal.filtfilt(b_high, a_high, audio_np[channel])
                        
                        # Mix: 85% oryginaÅ‚ + 15% boost wokalny - 5% wysokie
                        processed_audio[channel] = (
                            0.85 * audio_np[channel] + 
                            0.15 * vocal_boost - 
                            0.05 * high_content
                        )
                else:
                    processed_audio = audio_np
            else:
                processed_audio = audio_np
            
            # 4. ğŸ­ Subtelna charakterystyka gÅ‚osu uÅ¼ytkownika
            if self.speaker_embedding is not None:
                # Prosty pitch shift oparty na charakterystyce uÅ¼ytkownika
                # (w prawdziwym voice cloning byÅ‚yby zaawansowane transformacje)
                
                # Ekstrakcja charakterystyki z embedding (uproszczone)
                embedding_mean = float(self.speaker_embedding.mean())
                
                # Mapuj embedding na subtelnÄ… modulacjÄ™ pitch (-0.05 do +0.05)
                pitch_adjustment = np.tanh(embedding_mean) * 0.05
                
                # Prosty pitch shift przez time stretching
                if abs(pitch_adjustment) > 0.01:
                    stretch_factor = 1.0 + pitch_adjustment
                    
                    # Time stretch kaÅ¼dego kanaÅ‚u
                    for channel in range(processed_audio.shape[0]):
                        original_length = len(processed_audio[channel])
                        new_length = int(original_length * stretch_factor)
                        
                        # Interpolacja dla stretch/compress
                        x_old = np.linspace(0, 1, original_length)
                        x_new = np.linspace(0, 1, new_length)
                        stretched = np.interp(x_new, x_old, processed_audio[channel])
                        
                        # PrzywrÃ³Ä‡ oryginalnÄ… dÅ‚ugoÅ›Ä‡ przez resampling
                        if new_length != original_length:
                            x_resample = np.linspace(0, 1, original_length)
                            processed_audio[channel] = np.interp(x_resample, x_new, stretched)
            
            # 5. ğŸšï¸ Finalna normalizacja z naturalnym headroom
            # Konwertuj z powrotem do tensor
            audio = torch.from_numpy(processed_audio).float()
            
            # Gentle normalization z headroom
            max_amplitude = audio.abs().max()
            if max_amplitude > 0.1:  # Tylko jeÅ›li jest za gÅ‚oÅ›no
                target_amplitude = 0.7  # Naturalne headroom
                audio = audio * (target_amplitude / max_amplitude)
            
            # Zapisz przetworzone audio
            torchaudio.save(output_path, audio, sr)
            
            logger.info(f"ğŸ­ Ulepszone voice processing zakoÅ„czone: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"ğŸ’¥ BÅ‚Ä…d ulepszonego voice processing: {e}")
            return False
    
    def synthesize_with_voice_cloning(self, text: str, output_path: str) -> bool:
        """
        Syntezuje tekst z klonowaniem gÅ‚osu
        
        Args:
            text: Tekst do syntezowania po polsku
            output_path: ÅšcieÅ¼ka do pliku wyjÅ›ciowego
            
        Returns:
            bool: True jeÅ›li sukces
        """
        if not self.available:
            logger.error("Polish Voice Converter nie jest dostÄ™pny")
            return False
        
        try:
            logger.info(f"Synteza tekstu z voice cloning: '{text[:50]}...'")
            
            # KROK 1: Synteza bazowa uÅ¼ywajÄ…c Piper TTS
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                base_audio_path = tmp.name
            
            logger.info("Synteza bazowa z Piper TTS...")
            success = self.piper_tts.synthesize_text(text, base_audio_path)
            
            if not success or not os.path.exists(base_audio_path):
                logger.error("Synteza bazowa nie powiodÅ‚a siÄ™")
                return False
                
            base_size = os.path.getsize(base_audio_path)
            logger.info(f"Synteza bazowa zakoÅ„czona: {base_size} bytes")
            
            # KROK 2: Voice processing (klonowanie gÅ‚osu)
            logger.info("Aplikowanie voice cloning...")
            success = self.simple_voice_processing(base_audio_path, output_path)
            
            # Cleanup
            if os.path.exists(base_audio_path):
                os.unlink(base_audio_path)
            
            if success:
                final_size = os.path.getsize(output_path)
                logger.info(f"Voice cloning zakoÅ„czony sukcesem: {final_size} bytes")
                return True
            else:
                logger.error("Voice processing nie powiÃ³dÅ‚ siÄ™")
                return False
                
        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas syntezy z voice cloning: {e}")
            return False
    
    def test_synthesis(self) -> bool:
        """Test syntezy polskiego tekstu z voice cloning"""
        if not self.available:
            return False
            
        test_text = "Witaj! To jest test polskiego systemu syntezy mowy z klonowaniem gÅ‚osu. Czy brzmi naturalnie?"
        
        output_path = "test_voice_cloning.wav"
        
        try:
            success = self.synthesize_with_voice_cloning(test_text, output_path)
            if success and os.path.exists(output_path):
                file_size = os.path.getsize(output_path)
                logger.info(f"Test voice cloning zakoÅ„czony sukcesem: {file_size} bytes")
                return True
            else:
                logger.error("Test voice cloning nie powiÃ³dÅ‚ siÄ™")
                return False
        except Exception as e:
            logger.error(f"BÅ‚Ä…d podczas testu voice cloning: {e}")
            return False
    
    def get_info(self) -> Dict[str, Any]:
        """Zwraca informacje o pipeline"""
        return {
            "name": "Polish Voice Conversion Pipeline",
            "available": self.available,
            "piper_tts": self.piper_tts.get_info(),
            "speaker_extractor": self.speaker_extractor.get_info(),
            "speaker_embedding_path": self.speaker_embedding_path,
            "speaker_embedding_loaded": self.speaker_embedding is not None
        }

# Factory function
def get_voice_converter(speaker_embedding_path: str = "simple_speaker_embedding.pt") -> PolishVoiceConverter:
    """Tworzy instancjÄ™ Polish Voice Converter"""
    return PolishVoiceConverter(speaker_embedding_path)

if __name__ == "__main__":
    # Ustaw debug logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    # Test Polish Voice Conversion Pipeline
    print("ğŸ­ Test Polish Voice Conversion Pipeline")
    print("=" * 60)
    
    converter = get_voice_converter()
    
    # Informacje
    print("Voice Converter Info:")
    info = converter.get_info()
    for key, value in info.items():
        if isinstance(value, dict):
            print(f"  {key}:")
            for k, v in value.items():
                print(f"    {k}: {v}")
        else:
            print(f"  {key}: {value}")
    
    if not converter.is_available():
        print("âŒ Polish Voice Converter nie jest dostÄ™pny!")
        exit(1)
    
    # Test syntezy
    print("\nğŸ§ª Uruchamianie testu syntezy z voice cloning...")
    
    success = converter.test_synthesis()
    
    if success:
        print("âœ… Test zakoÅ„czony sukcesem!")
        
        # SprawdÅº plik wyjÅ›ciowy
        output_file = "test_voice_cloning.wav"
        if os.path.exists(output_file):
            file_size = os.path.getsize(output_file)
            print(f"âœ… Plik audio utworzony: {output_file} ({file_size} bytes)")
        else:
            print("âŒ Plik audio nie zostaÅ‚ utworzony")
    else:
        print("âŒ Test nie powiÃ³dÅ‚ siÄ™!")
